2017-11-02 10:33:14,686 Logfile at RelationNet/Nov-2/10-33-14/log.txt
2017-11-02 10:33:14,686 	DATA_DIR = /scratch/psn240/capstone/data/w-vs-qcd/pickles/
2017-11-02 10:33:14,687 	MODELS_DIR = models
2017-11-02 10:33:14,687 	MODEL_TYPES = ['RelationNet', 'RecNN-simple', 'RecNN-gated', 'MPNN']
2017-11-02 10:33:14,687 	TRANSFORMS = [<class 'architectures.relation_net.RelNNTransformConnected'>, <class 'architectures.recursive_net.GRNNTransformSimple'>, <class 'architectures.recursive_net.GRNNTransformGated'>, <class 'architectures.message_net.message_net.MPNNTransform'>]
2017-11-02 10:33:14,687 	add_cropped = False
2017-11-02 10:33:14,687 	batch_size = 64
2017-11-02 10:33:14,687 	bs = 9
2017-11-02 10:33:14,687 	debug = True
2017-11-02 10:33:14,687 	decay = 0.912
2017-11-02 10:33:14,688 	filename = antikt-kt
2017-11-02 10:33:14,688 	gpu = -1
2017-11-02 10:33:14,688 	leaves = False
2017-11-02 10:33:14,688 	load = None
2017-11-02 10:33:14,688 	model_type = 0
2017-11-02 10:33:14,688 	n_epochs = 3
2017-11-02 10:33:14,688 	n_features = 7
2017-11-02 10:33:14,688 	n_hidden = 1
2017-11-02 10:33:14,688 	n_iters = 1
2017-11-02 10:33:14,688 	n_train = 1000
2017-11-02 10:33:14,689 	n_valid = 200
2017-11-02 10:33:14,689 	password = deeplearning
2017-11-02 10:33:14,689 	recipient = None
2017-11-02 10:33:14,689 	restart = False
2017-11-02 10:33:14,689 	seed = 1
2017-11-02 10:33:14,689 	sender = results74207281@gmail.com
2017-11-02 10:33:14,689 	silent = False
2017-11-02 10:33:14,689 	step_size = 0.001
2017-11-02 10:33:14,689 	verbose = True
2017-11-02 10:33:14,690 	PID = 24525
2017-11-02 10:33:14,690 	Running on GPU: False
2017-11-02 10:33:14,690 Loading data...
2017-11-02 10:33:14,691 TF already computed. Loading it.
2017-11-02 10:33:16,976 Data loaded and already preprocessed
2017-11-02 10:33:24,751 Splitting into train and validation...
2017-11-02 10:33:24,752 	raw train size = 800
2017-11-02 10:33:24,752 	raw valid size = 200
2017-11-02 10:33:24,752 Cropping...
2017-11-02 10:33:24,753 85 (selected) + 115 (cropped) = 200
2017-11-02 10:33:24,754 	final train size = 800
2017-11-02 10:33:24,754 	final valid size = 85
2017-11-02 10:33:24,756 PredictFromParticleEmbedding (
  (transform): RelNNTransformConnected (
    (fc_u): Linear (7 -> 1)
    (fc_u1): Linear (1 -> 1)
    (fc_edge): Linear (1 -> 1)
  )
  (fc1): Linear (1 -> 1)
  (fc2): Linear (1 -> 1)
  (fc3): Linear (1 -> 1)
)
2017-11-02 10:33:24,756 Number of parameters: 18
2017-11-02 10:33:24,757 Training...
2017-11-02 10:33:24,757 epoch = 0
2017-11-02 10:33:24,757 step_size = 0.00100000
2017-11-02 10:33:24,757 batch# = 0
2017-11-02 10:33:24,758 Here 1
2017-11-02 10:33:25,119 Here 2
2017-11-02 10:33:25,400 NaN in 1/FPR

2017-11-02 10:33:25,401 Here 3
2017-11-02 10:33:25,401     0	~loss(train)=0.7384	loss(valid)=0.7384	roc_auc(valid)=0.5000	1/FPR @ TPR = 0.5: nan	Best 1/FPR @ TPR = 0.5: -inf
2017-11-02 10:33:25,401 Here 4
2017-11-02 10:33:25,401 batch# = 1
2017-11-02 10:33:25,402 Here 1
2017-11-02 10:33:25,609 Here 2
2017-11-02 10:33:25,610 Here 3
2017-11-02 10:33:25,610 Here 4
2017-11-02 10:33:25,610 batch# = 2
2017-11-02 10:33:25,611 Here 1
2017-11-02 10:33:25,820 Here 2
2017-11-02 10:33:25,821 Here 3
2017-11-02 10:33:25,821 Here 4
2017-11-02 10:33:25,821 batch# = 3
2017-11-02 10:33:25,821 Here 1
2017-11-02 10:33:26,000 Here 2
2017-11-02 10:33:26,001 Here 3
2017-11-02 10:33:26,001 Here 4
2017-11-02 10:33:26,001 batch# = 4
2017-11-02 10:33:26,001 Here 1
2017-11-02 10:33:26,222 Here 2
2017-11-02 10:33:26,223 Here 3
2017-11-02 10:33:26,223 Here 4
2017-11-02 10:33:26,223 batch# = 5
2017-11-02 10:33:26,224 Here 1
2017-11-02 10:33:26,403 Here 2
2017-11-02 10:33:26,404 Here 3
2017-11-02 10:33:26,404 Here 4
2017-11-02 10:33:26,404 batch# = 6
2017-11-02 10:33:26,404 Here 1
2017-11-02 10:33:26,655 Here 2
2017-11-02 10:33:26,656 Here 3
2017-11-02 10:33:26,656 Here 4
2017-11-02 10:33:26,656 batch# = 7
2017-11-02 10:33:26,656 Here 1
2017-11-02 10:33:26,985 Here 2
2017-11-02 10:33:26,986 Here 3
2017-11-02 10:33:26,986 Here 4
2017-11-02 10:33:26,986 batch# = 8
2017-11-02 10:33:26,986 Here 1
2017-11-02 10:33:27,184 Here 2
2017-11-02 10:33:27,185 Here 3
2017-11-02 10:33:27,185 Here 4
2017-11-02 10:33:27,185 batch# = 9
2017-11-02 10:33:27,185 Here 1
2017-11-02 10:33:27,448 Here 2
2017-11-02 10:33:27,449 Here 3
2017-11-02 10:33:27,449 Here 4
2017-11-02 10:33:27,449 batch# = 10
2017-11-02 10:33:27,449 Here 1
2017-11-02 10:33:27,556 Here 2
2017-11-02 10:33:27,557 Here 3
2017-11-02 10:33:27,557 Here 4
2017-11-02 10:33:27,558 batch# = 11
2017-11-02 10:33:27,558 Here 1
2017-11-02 10:33:27,674 Here 2
2017-11-02 10:33:27,674 Here 3
2017-11-02 10:33:27,674 Here 4
2017-11-02 10:33:27,675 batch# = 12
2017-11-02 10:33:27,675 Here 1
2017-11-02 10:33:27,837 Here 2
2017-11-02 10:33:27,837 Here 3
2017-11-02 10:33:27,837 Here 4
2017-11-02 10:33:27,838 epoch = 1
2017-11-02 10:33:27,838 step_size = 0.00091200
2017-11-02 10:33:27,838 batch# = 0
2017-11-02 10:33:27,838 Here 1
2017-11-02 10:33:27,986 Here 2
2017-11-02 10:33:28,255 NaN in 1/FPR

2017-11-02 10:33:28,256 Here 3
2017-11-02 10:33:28,256     0	~loss(train)=0.7346	loss(valid)=0.7346	roc_auc(valid)=0.5000	1/FPR @ TPR = 0.5: nan	Best 1/FPR @ TPR = 0.5: -inf
2017-11-02 10:33:28,256 Here 4
2017-11-02 10:33:28,256 batch# = 1
2017-11-02 10:33:28,257 Here 1
2017-11-02 10:33:28,429 Here 2
2017-11-02 10:33:28,430 Here 3
2017-11-02 10:33:28,430 Here 4
2017-11-02 10:33:28,430 batch# = 2
2017-11-02 10:33:28,430 Here 1
2017-11-02 10:33:28,563 Here 2
2017-11-02 10:33:28,563 Here 3
2017-11-02 10:33:28,563 Here 4
2017-11-02 10:33:28,564 batch# = 3
2017-11-02 10:33:28,564 Here 1
2017-11-02 10:33:28,710 Here 2
2017-11-02 10:33:28,711 Here 3
2017-11-02 10:33:28,711 Here 4
2017-11-02 10:33:28,711 batch# = 4
2017-11-02 10:33:28,711 Here 1
2017-11-02 10:33:28,848 Here 2
2017-11-02 10:33:28,849 Here 3
2017-11-02 10:33:28,849 Here 4
2017-11-02 10:33:28,849 batch# = 5
2017-11-02 10:33:28,849 Here 1
2017-11-02 10:33:29,045 Here 2
2017-11-02 10:33:29,046 Here 3
2017-11-02 10:33:29,046 Here 4
2017-11-02 10:33:29,046 batch# = 6
2017-11-02 10:33:29,047 Here 1
2017-11-02 10:33:29,446 Here 2
2017-11-02 10:33:29,446 Here 3
2017-11-02 10:33:29,446 Here 4
2017-11-02 10:33:29,447 batch# = 7
2017-11-02 10:33:29,447 Here 1
2017-11-02 10:33:29,607 Here 2
2017-11-02 10:33:29,608 Here 3
2017-11-02 10:33:29,608 Here 4
2017-11-02 10:33:29,608 batch# = 8
2017-11-02 10:33:29,608 Here 1
2017-11-02 10:33:29,799 Here 2
2017-11-02 10:33:29,800 Here 3
2017-11-02 10:33:29,800 Here 4
2017-11-02 10:33:29,800 batch# = 9
2017-11-02 10:33:29,801 Here 1
2017-11-02 10:33:29,988 Here 2
2017-11-02 10:33:29,989 Here 3
2017-11-02 10:33:29,989 Here 4
2017-11-02 10:33:29,989 batch# = 10
2017-11-02 10:33:29,989 Here 1
2017-11-02 10:33:30,306 Here 2
2017-11-02 10:33:30,307 Here 3
2017-11-02 10:33:30,307 Here 4
2017-11-02 10:33:30,307 batch# = 11
2017-11-02 10:33:30,307 Here 1
2017-11-02 10:33:30,643 Here 2
2017-11-02 10:33:30,645 Here 3
2017-11-02 10:33:30,645 Here 4
2017-11-02 10:33:30,645 batch# = 12
2017-11-02 10:33:30,645 Here 1
2017-11-02 10:33:30,801 Here 2
2017-11-02 10:33:30,802 Here 3
2017-11-02 10:33:30,802 Here 4
2017-11-02 10:33:30,802 epoch = 2
2017-11-02 10:33:30,802 step_size = 0.00083174
2017-11-02 10:33:30,802 batch# = 0
2017-11-02 10:33:30,802 Here 1
2017-11-02 10:33:30,997 Here 2
2017-11-02 10:33:31,254 NaN in 1/FPR

2017-11-02 10:33:31,254 Here 3
2017-11-02 10:33:31,255     0	~loss(train)=0.7311	loss(valid)=0.7311	roc_auc(valid)=0.5000	1/FPR @ TPR = 0.5: nan	Best 1/FPR @ TPR = 0.5: -inf
2017-11-02 10:33:31,255 Here 4
2017-11-02 10:33:31,255 batch# = 1
2017-11-02 10:33:31,255 Here 1
2017-11-02 10:33:31,399 Here 2
2017-11-02 10:33:31,400 Here 3
2017-11-02 10:33:31,400 Here 4
2017-11-02 10:33:31,400 batch# = 2
2017-11-02 10:33:31,401 Here 1
2017-11-02 10:33:31,750 Here 2
2017-11-02 10:33:31,751 Here 3
2017-11-02 10:33:31,751 Here 4
2017-11-02 10:33:31,751 batch# = 3
2017-11-02 10:33:31,752 Here 1
2017-11-02 10:33:31,902 Here 2
2017-11-02 10:33:31,902 Here 3
2017-11-02 10:33:31,903 Here 4
2017-11-02 10:33:31,903 batch# = 4
2017-11-02 10:33:31,903 Here 1
2017-11-02 10:33:32,093 Here 2
2017-11-02 10:33:32,094 Here 3
2017-11-02 10:33:32,094 Here 4
2017-11-02 10:33:32,094 batch# = 5
2017-11-02 10:33:32,094 Here 1
2017-11-02 10:33:32,222 Here 2
2017-11-02 10:33:32,223 Here 3
2017-11-02 10:33:32,223 Here 4
2017-11-02 10:33:32,223 batch# = 6
2017-11-02 10:33:32,224 Here 1
2017-11-02 10:33:32,404 Here 2
2017-11-02 10:33:32,405 Here 3
2017-11-02 10:33:32,405 Here 4
2017-11-02 10:33:32,405 batch# = 7
2017-11-02 10:33:32,405 Here 1
2017-11-02 10:33:32,530 Here 2
2017-11-02 10:33:32,531 Here 3
2017-11-02 10:33:32,531 Here 4
2017-11-02 10:33:32,531 batch# = 8
2017-11-02 10:33:32,531 Here 1
2017-11-02 10:33:32,712 Here 2
2017-11-02 10:33:32,712 Here 3
2017-11-02 10:33:32,712 Here 4
2017-11-02 10:33:32,713 batch# = 9
2017-11-02 10:33:32,713 Here 1
2017-11-02 10:33:32,848 Here 2
2017-11-02 10:33:32,849 Here 3
2017-11-02 10:33:32,849 Here 4
2017-11-02 10:33:32,850 batch# = 10
2017-11-02 10:33:32,850 Here 1
2017-11-02 10:33:32,983 Here 2
2017-11-02 10:33:32,984 Here 3
2017-11-02 10:33:32,984 Here 4
2017-11-02 10:33:32,984 batch# = 11
2017-11-02 10:33:32,985 Here 1
2017-11-02 10:33:33,133 Here 2
2017-11-02 10:33:33,133 Here 3
2017-11-02 10:33:33,133 Here 4
2017-11-02 10:33:33,134 batch# = 12
2017-11-02 10:33:33,134 Here 1
2017-11-02 10:33:33,318 Here 2
2017-11-02 10:33:33,319 Here 3
2017-11-02 10:33:33,319 Here 4
2017-11-02 10:33:33,319 FINISHED TRAINING
2017-11-02 10:33:33,319 Completed on Nov-2 at 10:33:33
