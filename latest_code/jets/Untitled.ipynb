{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "from data_ops.preprocessing import permute_by_pt\n",
    "from data_ops.preprocessing import extract\n",
    "from data_ops.preprocessing import sequentialize_by_pt\n",
    "from data_ops.preprocessing import randomize\n",
    "from data_ops.preprocessing import rewrite_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = '../../'\n",
    "#filename = 'antikt-kt-train.pickle'\n",
    "filename = 'antikt-kt-pileup25-new-train.pickle'\n",
    "path_to_preprocessed_dir = os.path.join(data_dir, 'preprocessed')\n",
    "path_to_preprocessed = os.path.join(path_to_preprocessed_dir, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, 'raw', filename), mode=\"rb\") as fd:\n",
    "            X, y = pickle.load(fd, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf = load_tf(args.data_dir, \"{}-train.pickle\".format(args.filename))\n",
    "    X, y = load_data(args.data_dir, \"{}-train.pickle\".format(args.filename))\n",
    "    for ij, jet in enumerate(X):\n",
    "        jet[\"content\"] = tf.transform(jet[\"content\"])\n",
    "\n",
    "    if args.n_train > 0:\n",
    "        indices = torch.randperm(len(X)).numpy()[:args.n_train]\n",
    "        X = [X[i] for i in indices]\n",
    "        y = y[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "m = nn.Threshold(0.5, 0)\n",
    "input = Variable(torch.randn(2))\n",
    "print(input)\n",
    "print(m(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = nn.Softmax()\n",
    "input = Variable(torch.randn(2, 3))\n",
    "print(input)\n",
    "print(m(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(input > 0.5).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = torch.FloatTensor(input.size()).zero_()+1\n",
    "B = torch.FloatTensor(input.size()).zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_adversarial(y_pred, y):\n",
    "        return -(y * torch.log(y_pred) + (1. - y) * torch.log(1. - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss_adversarial(A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "torch.log(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import Adam#, lr_scheduler\n",
    "import copy\n",
    "import numpy as np\n",
    "import logging\n",
    "import pickle\n",
    "import time\n",
    "import os\n",
    "import argparse\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from data_ops.wrapping import wrap\n",
    "from data_ops.wrapping import unwrap\n",
    "from data_ops.wrapping import wrap_X\n",
    "from data_ops.wrapping import unwrap_X\n",
    "\n",
    "from misc.constants import *\n",
    "from misc.handlers import ExperimentHandler\n",
    "from misc.loggers import StatsLogger\n",
    "\n",
    "from monitors.losses import *\n",
    "from monitors.monitors import *\n",
    "\n",
    "from architectures import PredictFromParticleEmbedding\n",
    "#from architectures import AdversarialParticleEmbedding\n",
    "\n",
    "from loading import load_data\n",
    "from loading import load_tf\n",
    "from loading import crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = 'antikt-kt'\n",
    "data_dir = '../../'\n",
    "tf = load_tf(data_dir, \"{}-train.pickle\".format(filename))\n",
    "X, y = load_data(data_dir, \"{}-train.pickle\".format(filename))\n",
    "for ij, jet in enumerate(X):\n",
    "    jet[\"content\"] = tf.transform(jet[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "''' ARGUMENTS '''\n",
    "'''----------------------------------------------------------------------- '''\n",
    "parser = argparse.ArgumentParser(description='Jets')\n",
    "\n",
    "# data args\n",
    "parser.add_argument(\"-f\", \"--filename\", type=str, default='antikt-kt')\n",
    "parser.add_argument(\"--data_dir\", type=str, default=DATA_DIR)\n",
    "parser.add_argument(\"-n\", \"--n_train\", type=int, default=-1)\n",
    "parser.add_argument(\"--n_valid\", type=int, default=27000)\n",
    "parser.add_argument(\"--dont_add_cropped\", action='store_true', default=False)\n",
    "parser.add_argument(\"-p\", \"--pileup\", action='store_true', default=False)\n",
    "\n",
    "# general model args\n",
    "parser.add_argument(\"-m\", \"--model_type\", help=\"index of the model you want to train - look in constants.py for the model list\", type=int, default=1)\n",
    "parser.add_argument(\"--features\", type=int, default=7)\n",
    "parser.add_argument(\"--hidden\", type=int, default=40)\n",
    "\n",
    "# logging args\n",
    "parser.add_argument(\"-s\", \"--silent\", action='store_true', default=False)\n",
    "parser.add_argument(\"-v\", \"--verbose\", action='store_true', default=False)\n",
    "parser.add_argument(\"--extra_tag\", type=int, default=0)\n",
    "\n",
    "# loading previous models args\n",
    "parser.add_argument(\"-l\", \"--load\", help=\"model directory from which we load a state_dict\", type=str, default=None)\n",
    "parser.add_argument(\"-r\", \"--restart\", help=\"restart a loaded model from where it left off\", action='store_true', default=False)\n",
    "\n",
    "# training args\n",
    "parser.add_argument(\"-e\", \"--epochs\", type=int, default=50)\n",
    "parser.add_argument(\"-b\", \"--batch_size\", type=int, default=100)\n",
    "parser.add_argument(\"-a\", \"--step_size\", type=float, default=0.001)\n",
    "parser.add_argument(\"-d\", \"--decay\", type=float, default=.94)\n",
    "\n",
    "# computing args\n",
    "parser.add_argument(\"--seed\", help=\"Random seed used in torch and numpy\", type=int, default=None)\n",
    "parser.add_argument(\"-g\", \"--gpu\", type=str, default=\"\")\n",
    "\n",
    "# MPNN\n",
    "parser.add_argument(\"--not_leaves\", action='store_true')\n",
    "parser.add_argument(\"-i\", \"--iters\", type=int, default=0)\n",
    "\n",
    "# email\n",
    "parser.add_argument(\"--sender\", type=str, default=\"results74207281@gmail.com\")\n",
    "parser.add_argument(\"--password\", type=str, default=\"deeplearning\")\n",
    "\n",
    "# debugging\n",
    "parser.add_argument(\"--debug\", help=\"sets everything small for fast model debugging. use in combination with ipdb\", action='store_true', default=False)\n",
    "\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if args.debug:\n",
    "    args.hidden = 1\n",
    "    args.batch_size = 9\n",
    "    args.verbose = True\n",
    "    args.epochs = 3\n",
    "    args.n_train = 1000\n",
    "    args.seed = 1\n",
    "    args.iters = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, Transform, model_type = TRANSFORMS[args.model_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'recnn/simple'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/10/2017 08:59:34 AM \tbatch_size = 100\n",
      "12/10/2017 08:59:34 AM \tdata_dir = data/w-vs-qcd/pickles\n",
      "12/10/2017 08:59:34 AM \tdebug = False\n",
      "12/10/2017 08:59:34 AM \tdecay = 0.94\n",
      "12/10/2017 08:59:34 AM \tdont_add_cropped = False\n",
      "12/10/2017 08:59:34 AM \tepochs = 50\n",
      "12/10/2017 08:59:34 AM \textra_tag = 0\n",
      "12/10/2017 08:59:34 AM \tfeatures = 7\n",
      "12/10/2017 08:59:34 AM \tfilename = /Users/Bangz/Library/Jupyter/runtime/kernel-19e504c5-4cef-417d-bfbc-287b45703803.json\n",
      "12/10/2017 08:59:34 AM \tgpu = \n",
      "12/10/2017 08:59:34 AM \thidden = 40\n",
      "12/10/2017 08:59:34 AM \titers = 0\n",
      "12/10/2017 08:59:34 AM \tload = None\n",
      "12/10/2017 08:59:34 AM \tmodel_type = 1\n",
      "12/10/2017 08:59:34 AM \tn_train = -1\n",
      "12/10/2017 08:59:34 AM \tn_valid = 27000\n",
      "12/10/2017 08:59:34 AM \tnot_leaves = False\n",
      "12/10/2017 08:59:34 AM \tpassword = deeplearning\n",
      "12/10/2017 08:59:34 AM \tpileup = False\n",
      "12/10/2017 08:59:34 AM \trecipient = psn240@nyu.edu\n",
      "12/10/2017 08:59:34 AM \trestart = False\n",
      "12/10/2017 08:59:34 AM \troot_exp_dir = models/recnn/simple/0\n",
      "12/10/2017 08:59:34 AM \tseed = 43717\n",
      "12/10/2017 08:59:34 AM \tsender = results74207281@gmail.com\n",
      "12/10/2017 08:59:34 AM \tsilent = False\n",
      "12/10/2017 08:59:34 AM \tstep_size = 0.001\n",
      "12/10/2017 08:59:34 AM \tverbose = False\n",
      "12/10/2017 08:59:34 AM \tPID = 37484\n",
      "12/10/2017 08:59:34 AM \tNot running on GPU\n"
     ]
    }
   ],
   "source": [
    "args.root_exp_dir = os.path.join(MODELS_DIR,model_type, str(args.iters))\n",
    "args.recipient = 'psn240@nyu.edu'\n",
    "eh = ExperimentHandler(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logdict = dict(\n",
    "                epoch=1,\n",
    "                iteration=1,\n",
    "                yy=[1.0],\n",
    "                yy_pred=[1,0],\n",
    "                w_valid=[1, 2, 3],\n",
    "                #w_valid=w_valid,\n",
    "                train_loss=0.5,\n",
    "                valid_loss=0.5,\n",
    "                settings=settings,\n",
    "                #model=model\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_kwargs = {\n",
    "            'features': args.features,\n",
    "            'hidden': args.hidden,\n",
    "            'iters': args.iters,\n",
    "            'leaves': 10,\n",
    "            'batch' : args.batch_size,\n",
    "        }\n",
    "        \n",
    "settings = {\n",
    "            \"transform\": Transform,\n",
    "            #\"predict\": Predict,\n",
    "            \"model_kwargs\": model_kwargs,\n",
    "            \"step_size\": args.step_size,\n",
    "            \"args\": args,\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "roc_auc = ROCAUC()\n",
    "inv_fpr = InvFPR()\n",
    "best_inv_fpr = Best(inv_fpr)\n",
    "epoch_counter = Regurgitate('epoch')\n",
    "batch_counter = Regurgitate('iteration')\n",
    "valid_loss = Regurgitate('valid_loss')\n",
    "train_loss = Regurgitate('train_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "monitors = [\n",
    "            epoch_counter,\n",
    "            batch_counter,\n",
    "            roc_auc,\n",
    "            inv_fpr,\n",
    "            best_inv_fpr,\n",
    "            valid_loss,\n",
    "            train_loss,\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "monitors = {m.name: m for m in monitors}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_inv_fpr': <monitors.monitors.Best at 0x111f45240>,\n",
       " 'epoch': <monitors.monitors.Regurgitate at 0x111f451d0>,\n",
       " 'inv_fpr': <monitors.monitors.InvFPR at 0x111f45198>,\n",
       " 'iteration': <monitors.monitors.Regurgitate at 0x111f450b8>,\n",
       " 'roc_auc': <monitors.monitors.ROCAUC at 0x111f453c8>,\n",
       " 'train_loss': <monitors.monitors.Regurgitate at 0x111f45160>,\n",
       " 'valid_loss': <monitors.monitors.Regurgitate at 0x111f45128>}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monitors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kwargs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-e1fa795dec7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstats_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmonitors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mstats_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'kwargs' is not defined"
     ]
    }
   ],
   "source": [
    "stats_dict = {}\n",
    "for name, monitor in monitors.items():\n",
    "    stats_dict[name] = monitor(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred_40 = np.load('../../Y_pred_40.csv.npy')\n",
    "Y_test_40 = np.load('../../Y_test_40.csv.npy')\n",
    "Y_pred_50 = np.load('../../Y_pred_50.csv.npy')\n",
    "Y_test_50 = np.load('../../Y_test_50.csv.npy')\n",
    "Y_pred_60 = np.load('../../Y_pred_60.csv.npy')\n",
    "Y_test_60 = np.load('../../Y_test_60.csv.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred_40 = np.load('../../Y_non_pileup_pred_40.csv.npy')\n",
    "Y_test_40 = np.load('../../Y_non_pileup_test_40.csv.npy')\n",
    "Y_pred_50 = np.load('../../Y_non_pileup_pred_50.csv.npy')\n",
    "Y_test_50 = np.load('../../Y_non_pileup_test_50.csv.npy')\n",
    "Y_pred_60 = np.load('../../Y_non_pileup_pred_60.csv.npy')\n",
    "Y_test_60 = np.load('../../Y_non_pileup_test_60.csv.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.hist(Y_pred_40[Y_test_40==0], bins=100, normed=1, histtype=\"step\", label=\"$p(f(X)=0|Z=40)$\", color='red')\n",
    "plt.hist(Y_pred_50[Y_test_50==0], bins=100, normed=1, histtype=\"step\", label=\"$p(f(X)=0|Z=50)$\", color='blue')\n",
    "plt.hist(Y_pred_60[Y_test_60==0], bins=100, normed=1, histtype=\"step\", label=\"$p(f(X)=0|Z=60)$\", color='black')\n",
    "#plt.title('Conditional probabilites densities of the desicision scores at Z = 40, 50, 60')\n",
    "plt.legend(loc=\"best\")\n",
    "#plt.ylim(0,4)\n",
    "plt.xlabel(\"$f(X)$\")\n",
    "plt.ylabel(\"$p(f(X))$\")\n",
    "#plt.legend(loc=\"upper left\")\n",
    "#figure_filename = \n",
    "#plot_save(figure_filename)\n",
    "plt.savefig('Pileup_0.png')\n",
    "#plt.savefig('Pileup_0.png')\n",
    "#plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.hist(Y_pred_40[Y_test_40==1], bins=100, normed=1, histtype=\"step\", label=\"$p(f(X)=1|Z=40)$\", color='red')\n",
    "plt.hist(Y_pred_50[Y_test_50==1], bins=100, normed=1, histtype=\"step\", label=\"$p(f(X)=1|Z=50)$\", color='blue')\n",
    "plt.hist(Y_pred_60[Y_test_60==1], bins=100, normed=1, histtype=\"step\", label=\"$p(f(X)=1|Z=60)$\", color='black')\n",
    "#plt.title('Conditional probabilites densities of the desicision scores at Z = 40, 50, 60')\n",
    "#plt.legend(loc=\"best\")\n",
    "#plt.ylim(0,4)\n",
    "plt.xlabel(\"$f(X)$\")\n",
    "plt.ylabel(\"$p(f(X))$\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "#figure_filename = \n",
    "#plot_save(figure_filename)\n",
    "plt.savefig('Pileup_1.png')\n",
    "#plt.savefig('Non_Adv_Pileup_1.png')\n",
    "#plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_adv = np.load('../../adv_loss.csv.npy')\n",
    "loss_rnn = np.load('../../rnn_loss.csv.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53900"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loss_adv)\n",
    "len(loss_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.plot(loss_adv, label=\"$Advserial loss$\", color='red')\n",
    "plt.plot(loss_rnn, label=\"$Classifier loss$\", color='blue')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig('loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
